{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "KDNPMCnItCl-"
      },
      "outputs": [],
      "source": [
        "# LIBRARIES #\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import io\n",
        "import sklearn\n",
        "import sklearn.metrics  as metrics\n",
        "import sklearn.cluster as cluster\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# READ CSV #\n",
        "warnings.filterwarnings('ignore')\n",
        "data = pd.read_csv('/content/student-por.csv', sep=\",\")"
      ],
      "metadata": {
        "id": "kowRfnwMtM0o"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "id": "1aVMK9WGoESz",
        "outputId": "51a59f70-5701-42e2-f048-8ae4160f3c38"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
              "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
              "mean    16.744222    2.514638    2.306626    1.568567    1.930663    0.221880   \n",
              "std      1.218138    1.134552    1.099931    0.748660    0.829510    0.593235   \n",
              "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
              "25%     16.000000    2.000000    1.000000    1.000000    1.000000    0.000000   \n",
              "50%     17.000000    2.000000    2.000000    1.000000    2.000000    0.000000   \n",
              "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
              "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
              "\n",
              "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
              "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
              "mean     3.930663    3.180277    3.184900    1.502311    2.280431    3.536210   \n",
              "std      0.955717    1.051093    1.175766    0.924834    1.284380    1.446259   \n",
              "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
              "25%      4.000000    3.000000    2.000000    1.000000    1.000000    2.000000   \n",
              "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
              "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
              "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
              "\n",
              "         absences          G1          G2          G3  \n",
              "count  649.000000  649.000000  649.000000  649.000000  \n",
              "mean     3.659476   11.399076   11.570108   11.906009  \n",
              "std      4.640759    2.745265    2.913639    3.230656  \n",
              "min      0.000000    0.000000    0.000000    0.000000  \n",
              "25%      0.000000   10.000000   10.000000   10.000000  \n",
              "50%      2.000000   11.000000   11.000000   12.000000  \n",
              "75%      6.000000   13.000000   13.000000   14.000000  \n",
              "max     32.000000   19.000000   19.000000   19.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28ca5d99-b521-47d0-8640-7480db7be9df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>traveltime</th>\n",
              "      <th>studytime</th>\n",
              "      <th>failures</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "      <td>649.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>16.744222</td>\n",
              "      <td>2.514638</td>\n",
              "      <td>2.306626</td>\n",
              "      <td>1.568567</td>\n",
              "      <td>1.930663</td>\n",
              "      <td>0.221880</td>\n",
              "      <td>3.930663</td>\n",
              "      <td>3.180277</td>\n",
              "      <td>3.184900</td>\n",
              "      <td>1.502311</td>\n",
              "      <td>2.280431</td>\n",
              "      <td>3.536210</td>\n",
              "      <td>3.659476</td>\n",
              "      <td>11.399076</td>\n",
              "      <td>11.570108</td>\n",
              "      <td>11.906009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.218138</td>\n",
              "      <td>1.134552</td>\n",
              "      <td>1.099931</td>\n",
              "      <td>0.748660</td>\n",
              "      <td>0.829510</td>\n",
              "      <td>0.593235</td>\n",
              "      <td>0.955717</td>\n",
              "      <td>1.051093</td>\n",
              "      <td>1.175766</td>\n",
              "      <td>0.924834</td>\n",
              "      <td>1.284380</td>\n",
              "      <td>1.446259</td>\n",
              "      <td>4.640759</td>\n",
              "      <td>2.745265</td>\n",
              "      <td>2.913639</td>\n",
              "      <td>3.230656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28ca5d99-b521-47d0-8640-7480db7be9df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28ca5d99-b521-47d0-8640-7480db7be9df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28ca5d99-b521-47d0-8640-7480db7be9df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FIRST APPROACH TO THE DATASET #\n",
        "\n",
        "# columns names #\n",
        "data_names = ['school', 'sex', 'age', 'address', 'family_size', 'parent_cohabition_status', 'mother_education', 'father_education','mother_job', 'father_job', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'school_support', 'family_support', 'paid', 'extra_curricular_activities', 'nursery', 'higher', 'internet_access', 'romantic', 'famrel', 'freetime', 'going_out', 'workday_alcohol', 'weekend_alcohol', 'health', 'absences','grade_period1', 'grade_period2', 'final_grade' ]\n",
        "data.columns = data_names\n",
        "\n",
        "# numerical vs categorical columns #\n",
        "numerical_columns = ['age', 'mother_education', 'father_education', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'going_out', 'workday_alcohol', 'weekend_alcohol', 'health', 'absences', 'grade_period1','grade_period2', 'final_grade']\n",
        "categorical_columns = [\"school\",\"sex\",'address', 'family_size', 'parent_cohabition_status','mother_job', 'father_job', 'reason', 'guardian',\"school_support\", \"family_support\",'paid', 'extra_curricular_activities', 'nursery', 'higher', 'internet_access', 'romantic']\n"
      ],
      "metadata": {
        "id": "RxuRRRKztR-p"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN THE DATABASE # \n",
        "\n",
        "# 3. Get the dummies so that it is easier to work. \n",
        "# This is, transform the categorical columns into numerical ones. \n",
        "data_clean = pd.get_dummies(data, columns=categorical_columns)\n",
        "\n",
        "# 4. Transform the data. \n",
        "# we need to standarize the data to take into consideration variations in measurments, units and scales. \n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data_clean[numerical_columns])\n",
        "scaled_dataframe = pd.DataFrame(scaled_data, columns = numerical_columns)  \n",
        "scaled_dataframe.head()\n",
        "\n",
        "for column in numerical_columns:\n",
        "  data_clean.append(scaled_dataframe[column])\n",
        "  data_clean[column] = scaled_dataframe[column]"
      ],
      "metadata": {
        "id": "U_lOXKQ7tWAC"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LINEAR REGRESSION #\n",
        "\n",
        "# 1. Split into training and testing data.\n",
        "boolean_mask = data_clean.columns.isin(['age', 'mother_education', 'father_education', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'going_out',\n",
        "       'workday_alcohol', 'weekend_alcohol', 'health', 'absences', 'grade_period1', 'grade_period2', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U',\n",
        "       'family_size_GT3', 'family_size_LE3', 'parent_cohabition_status_A', 'parent_cohabition_status_T', 'mother_job_at_home', 'mother_job_health',\n",
        "       'mother_job_other', 'mother_job_services', 'mother_job_teacher', 'father_job_at_home', 'father_job_health', 'father_job_other','father_job_services', \n",
        "       'father_job_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', \n",
        "       'school_support_yes','family_support_yes', 'paid_yes', 'extra_curricular_activities_yes', 'nursery_yes', 'higher_yes', 'internet_access_yes','romantic_yes'])\n",
        "sc = data_clean.columns[boolean_mask]\n",
        "X=data_clean[sc]\n",
        "\n",
        "boolean_mask_target = data_clean.columns.isin([\"final_grade\"])\n",
        "s = data_clean.columns[boolean_mask_target]\n",
        "y=data_clean[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# 2. Fit the model, get the prediction and get the accuracy.\n",
        "linear_model=LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "print(\"Linear regression:\")\n",
        "\n",
        "y_pred = linear_model.predict(X_train)\n",
        "\n",
        "print(\"Accuracy:\", linear_model.score(X_test,y_test))   # linear_model.score uses R-squared metric by default\n",
        "\n",
        "mse_tot = mean_squared_error(y_train, y_pred)  \n",
        "\n",
        "print(\"Mean squared error: %.10f\" % mse_tot)  \n",
        "\n",
        "# 3. Get the coefficients of the regression model:\n",
        "coefficient={}\n",
        "for coef, feat in zip(linear_model.coef_,X.columns):\n",
        "  coefficient[feat]=coef\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiaM6AREVpHU",
        "outputId": "372d741c-4ecf-4434-df76-298dd2cfba8b"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression:\n",
            "Accuracy: 0.7961384129232629\n",
            "Mean squared error: 0.1287854281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rescaled = y_pred * data[\"final_grade\"].std() + data[\"final_grade\"].mean()\n",
        "# print(y_pred_rescaled)   # these are the predicted grades in their original form\n",
        "print(\"\\n\", \"Mean of predicted grades:\", y_pred_rescaled.mean())\n",
        "\n",
        "# Our model predicts a slightly lower mean of the grades than in database. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuvNbZELqYQh",
        "outputId": "e84a891e-256a-4fba-b047-18696ecc9116"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Mean of predicted grades: 11.863141376517305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a function to determine which will be the best alpha value for Lasso regression in following cell.\n",
        "alphas = np.arange(0,1,0.001).tolist()\n",
        "def best_alpha(X, y, alpha_values=alphas):\n",
        "    \"\"\"\n",
        "    Here we can test which the best alpha value is, using cross-validation for Lasso model.\n",
        "\n",
        "    X is a feature matrix and y is a target vector. We will test all alpha values in the list of alpha values.\n",
        "    \"\"\"\n",
        "    \n",
        "    lasso = LassoCV(alphas=alpha_values, cv=5, random_state=42)\n",
        "    lasso.fit(X, y)\n",
        "    \n",
        "    best_alpha = lasso.alpha_\n",
        "    \n",
        "    return best_alpha"
      ],
      "metadata": {
        "id": "0igE4PNjrFG0"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LASSO REGRESSION #\n",
        "\n",
        "# 1. Split into training and testing data.\n",
        "boolean_mask = data_clean.columns.isin(['age', 'mother_education', 'father_education', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'going_out',\n",
        "       'workday_alcohol', 'weekend_alcohol', 'health', 'absences', 'grade_period1', 'grade_period2', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U',\n",
        "       'family_size_GT3', 'family_size_LE3', 'parent_cohabition_status_A', 'parent_cohabition_status_T', 'mother_job_at_home', 'mother_job_health',\n",
        "       'mother_job_other', 'mother_job_services', 'mother_job_teacher', 'father_job_at_home', 'father_job_health', 'father_job_other','father_job_services', \n",
        "       'father_job_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', \n",
        "       'school_support_yes','family_support_yes', 'paid_yes', 'extra_curricular_activities_yes', 'nursery_yes', 'higher_yes', 'internet_access_yes','romantic_yes'])\n",
        "sc = data_clean.columns[boolean_mask]\n",
        "X=data_clean[sc]\n",
        "\n",
        "boolean_mask_target = data_clean.columns.isin([\"final_grade\"])\n",
        "s = data_clean.columns[boolean_mask_target]\n",
        "y=data_clean[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# 2. Fit the model and get the accuracy.\n",
        "best_alpha_for_lasso = best_alpha(X_train, y_train)\n",
        "print(\"The alpha value we will use is:\", best_alpha_for_lasso)\n",
        "lasso_model=Lasso(alpha=best_alpha_for_lasso)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make the predictions.\n",
        "y_pred = lasso_model.predict(X_test)\n",
        "\n",
        "\n",
        "# 4. Get the slope and the intercept. \n",
        "# y = mx + b, where m represents the slope and b represents the y-intercept.\n",
        "print(\"Slope\",lasso_model.coef_[0])\n",
        "print(\"Intercept:\",lasso_model.intercept_)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Evaluate the performance of our model\n",
        "# Method 1: mean squared error\n",
        "# Disadvantage it's difficult to evaluate the performance of the model using MSE as the value of MSE can vary from 0 to any larger number\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "# Method 2: R2.\n",
        "# The value of R2 varies between 0 and 1. \n",
        "r2=lasso_model.score(X_test,y_test)\n",
        "\n",
        "print(\"R2:\",r2)\n",
        "\n",
        "\n",
        "# 6. Get Lasso coefficients and select a few features to improve the model accuracy\n",
        "sel = SelectFromModel(lasso_model)\n",
        "removed_features = X_train.columns[(sel.estimator.coef_ == 0).ravel().tolist()]\n",
        "chosen_features = X_train.columns[(sel.estimator.coef_ != 0).ravel().tolist()]\n",
        "\n",
        "print(\"\\n\", chosen_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNJltvi4aawY",
        "outputId": "fbd19431-365d-482d-fb52-f18beda1409c"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The alpha value we will use is: 0.036000000000000004\n",
            "Slope -0.0\n",
            "Intercept: [-0.00595664]\n",
            "\n",
            "\n",
            "Mean squared error: 0.11086818940934748\n",
            "R2: 0.8584082164838525\n",
            "\n",
            " Index(['failures', 'freetime', 'workday_alcohol', 'grade_period1',\n",
            "       'grade_period2'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LASSO REGRESSION AFTER FEATURE SELECTION #\n",
        "\n",
        "boolean_mask = data_clean.columns.isin(chosen_features.tolist())\n",
        "sc = data_clean.columns[boolean_mask]\n",
        "X=data_clean[sc]\n",
        "\n",
        "boolean_mask_target = data_clean.columns.isin([\"final_grade\"])\n",
        "s = data_clean.columns[boolean_mask_target]\n",
        "y=data_clean[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# 2. Fit the model and get the accuracy.\n",
        "# best_alpha_for_lasso = best_alpha(X_train, y_train)\n",
        "# print(\"The alpha value we will use is:\", best_alpha_for_lasso)\n",
        "lasso_model=Lasso(alpha=best_alpha_for_lasso)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make the predictions.\n",
        "y_pred = lasso_model.predict(X_test)\n",
        "\n",
        "# 4. Get the slope and the intercept. \n",
        "# y = mx + b, where m represents the slope and b represents the y-intercept.\n",
        "print(\"Slope\",lasso_model.coef_[0])\n",
        "print(\"Intercept:\",lasso_model.intercept_)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Evaluate the performance of our model\n",
        "# Method 1: mean squared error\n",
        "# Disadvantage it's difficult to evaluate the performance of the model using MSE as the value of MSE can vary from 0 to any larger number\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "# Method 2: R2.\n",
        "# The value of R2 varies between 0 and 1. \n",
        "r2=lasso_model.score(X_test,y_test)\n",
        "print(\"R2:\",r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc05nCV7s9b5",
        "outputId": "4c0f438a-d361-495b-a0e0-ef0a2fe77a45"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope -0.014504876427145116\n",
            "Intercept: [-0.00709969]\n",
            "\n",
            "\n",
            "Mean squared error: 0.1178833578671443\n",
            "R2: 0.8666970728111669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-4, 4, 1)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual final grade\")\n",
        "plt.ylabel(\"Predicted final grade\")\n",
        "plt.plot(x, x, color='m')\n",
        "plt.title(\"Actual vs. predicted final grade, Lasso model\")\n",
        "plt.grid(alpha=0.5); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "I9yypZ2TlTls",
        "outputId": "f3dc04a3-81bc-4c6d-ed80-371bf9414623"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rescaled = y_pred * data[\"final_grade\"].std() + data[\"final_grade\"].mean()\n",
        "# print(y_pred_rescaled)   # these are the predicted grades in their original form\n",
        "print(\"\\n\", \"Mean of predicted grades:\", y_pred_rescaled.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0IdXEMUmfff",
        "outputId": "95de365d-6fe3-4a75-8c28-2f9007eb1867"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Mean of predicted grades: 11.969186871567567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that, so far, we get an accuracy of the linear regression model of approximately 0.796 (79.6%). \n",
        "\n",
        "The Lasso regression model gets an accuracy of approximately 0.858 (85.8%), but after feature selection it gets an accuracy of approximately 0.867 (86.7%).\n",
        "\n",
        "All of these results differs for every run since the data is splitted randomly with shuffle = True. \n",
        "\n",
        "One thing that is important to note is that two of the features that affects these results the most are 'grade_period1' and 'grade_period2', which are also measures of grades. These have, as we can see, a very high correlation with the final grade. \n",
        "\n",
        "We should try just how much the current accuracy depends on these by removing them from the data."
      ],
      "metadata": {
        "id": "1g-Mx2fG--oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN THE DATABASE # \n",
        "\n",
        "# 1. Drop the columns that we are not going to use.\n",
        "data_clean = data.drop(['grade_period1', 'grade_period2'], axis=1)\n",
        "numerical_columns_new = ['age', 'mother_education', 'father_education', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'going_out', 'workday_alcohol', 'weekend_alcohol', 'health', 'absences', 'final_grade']"
      ],
      "metadata": {
        "id": "yXtHbTcqA63u"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLEAN THE DATABASE # \n",
        "\n",
        "# 3. Get the dummies so that it is easier to work. \n",
        "# This is, transform the categorical columns into numerical ones. \n",
        "data_clean = pd.get_dummies(data_clean, columns=categorical_columns)\n",
        "\n",
        "# 4. Transform the data. \n",
        "# we need to standarize the data to take into consideration variations in measurments, units and scales. \n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(data_clean[numerical_columns_new])\n",
        "scaled_dataframe = pd.DataFrame(scaled_data, columns = numerical_columns_new)  \n",
        "scaled_dataframe.head()\n",
        "\n",
        "for column in numerical_columns_new:\n",
        "  data_clean.append(scaled_dataframe[column])\n",
        "  data_clean[column] = scaled_dataframe[column]"
      ],
      "metadata": {
        "id": "uHZF0NGLAolf"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LASSO REGRESSION #\n",
        "\n",
        "# 1. Split into training and testing data.\n",
        "boolean_mask = data_clean.columns.isin(['age', 'mother_education', 'father_education', 'traveltime', 'studytime', 'failures', 'famrel', 'freetime', 'going_out',\n",
        "       'workday_alcohol', 'weekend_alcohol', 'health', 'absences', 'school_GP', 'school_MS', 'sex_F', 'sex_M', 'address_R', 'address_U',\n",
        "       'family_size_GT3', 'family_size_LE3', 'parent_cohabition_status_A', 'parent_cohabition_status_T', 'mother_job_at_home', 'mother_job_health',\n",
        "       'mother_job_other', 'mother_job_services', 'mother_job_teacher', 'father_job_at_home', 'father_job_health', 'father_job_other','father_job_services', \n",
        "       'father_job_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', \n",
        "       'school_support_yes','family_support_yes', 'paid_yes', 'extra_curricular_activities_yes', 'nursery_yes', 'higher_yes', 'internet_access_yes','romantic_yes'])\n",
        "sc = data_clean.columns[boolean_mask]\n",
        "X=data_clean[sc]\n",
        "\n",
        "boolean_mask_target = data_clean.columns.isin([\"final_grade\"])\n",
        "s = data_clean.columns[boolean_mask_target]\n",
        "y=data_clean[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# 2. Fit the model and get the accuracy.\n",
        "best_alpha_for_lasso = best_alpha(X_train, y_train)\n",
        "print(\"The alpha value we will use is:\", best_alpha_for_lasso)\n",
        "lasso_model=Lasso(alpha=best_alpha_for_lasso)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make the predictions.\n",
        "y_pred = lasso_model.predict(X_test)\n",
        "\n",
        "\n",
        "# 4. Get the slope and the intercept. \n",
        "# y = mx + b, where m represents the slope and b represents the y-intercept.\n",
        "print(\"Slope\",lasso_model.coef_[0])\n",
        "print(\"Intercept:\",lasso_model.intercept_)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Evaluate the performance of our model\n",
        "# Method 1: mean squared error\n",
        "# Disadvantage it's difficult to evaluate the performance of the model using MSE as the value of MSE can vary from 0 to any larger number\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "# Method 2: R2.\n",
        "# The value of R2 varies between 0 and 1. \n",
        "r2=lasso_model.score(X_test,y_test)\n",
        "\n",
        "print(\"R2:\",r2)\n",
        "\n",
        "\n",
        "# 6. Get Lasso coefficients and select a few features to improve the model accuracy\n",
        "sel = SelectFromModel(lasso_model)\n",
        "removed_features = X_train.columns[(sel.estimator.coef_ == 0).ravel().tolist()]\n",
        "chosen_features = X_train.columns[(sel.estimator.coef_ != 0).ravel().tolist()]\n",
        "\n",
        "print(\"\\n\", chosen_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS34w3MEB9O2",
        "outputId": "9f9d0a0f-14d9-45d3-e20b-942a23c2190f"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The alpha value we will use is: 0.017\n",
            "Slope 0.0\n",
            "Intercept: [-0.5249474]\n",
            "\n",
            "\n",
            "Mean squared error: 0.7418161734821966\n",
            "R2: 0.23576267289296693\n",
            "\n",
            " Index(['mother_education', 'father_education', 'studytime', 'failures',\n",
            "       'freetime', 'workday_alcohol', 'weekend_alcohol', 'health', 'absences',\n",
            "       'school_GP', 'sex_F', 'address_R', 'address_U', 'family_size_GT3',\n",
            "       'reason_other', 'reason_reputation', 'guardian_father',\n",
            "       'guardian_mother', 'school_support_yes',\n",
            "       'extra_curricular_activities_yes', 'higher_yes', 'internet_access_yes',\n",
            "       'romantic_yes'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LASSO REGRESSION AFTER FEATURE SELECTION #\n",
        "\n",
        "boolean_mask = data_clean.columns.isin(chosen_features.tolist())\n",
        "sc = data_clean.columns[boolean_mask]\n",
        "X=data_clean[sc]\n",
        "\n",
        "boolean_mask_target = data_clean.columns.isin([\"final_grade\"])\n",
        "s = data_clean.columns[boolean_mask_target]\n",
        "y=data_clean[s]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "\n",
        "# 2. Fit the model and get the accuracy.\n",
        "# best_alpha_for_lasso = best_alpha(X_train, y_train)\n",
        "# print(\"The alpha value we will use is:\", best_alpha_for_lasso)\n",
        "lasso_model=Lasso(alpha=best_alpha_for_lasso)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make the predictions.\n",
        "y_pred = lasso_model.predict(X_test)\n",
        "\n",
        "# 4. Get the slope and the intercept. \n",
        "# y = mx + b, where m represents the slope and b represents the y-intercept.\n",
        "print(\"Slope\",lasso_model.coef_[0])\n",
        "print(\"Intercept:\",lasso_model.intercept_)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 5. Evaluate the performance of our model\n",
        "# Method 1: mean squared error\n",
        "# Disadvantage it's difficult to evaluate the performance of the model using MSE as the value of MSE can vary from 0 to any larger number\n",
        "mse = mean_squared_error(y_test,y_pred)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "# Method 2: R2.\n",
        "# The value of R2 varies between 0 and 1. \n",
        "r2=lasso_model.score(X_test,y_test)\n",
        "print(\"R2:\",r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yryJcejFCPPn",
        "outputId": "c6af43f0-7167-4e35-ba78-b77063b82fe2"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope 0.06490601260957445\n",
            "Intercept: [-0.66797404]\n",
            "\n",
            "\n",
            "Mean squared error: 0.8579994386448625\n",
            "R2: 0.2415204764280282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we suspected, the accuracy gets much worse when these features are removed."
      ],
      "metadata": {
        "id": "MZ0GS8fgCVzp"
      }
    }
  ]
}